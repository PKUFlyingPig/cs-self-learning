# Andrej Karpathy LLM Zero to Hero ç³»åˆ—è§†é¢‘

## è¯¾ç¨‹ç®€ä»‹

- æ‰€å±å¤§å­¦ï¼š
- å…ˆä¿®è¦æ±‚ï¼š
- ç¼–ç¨‹è¯­è¨€ï¼špython
- è¯¾ç¨‹éš¾åº¦ï¼šğŸŒŸ
- é¢„è®¡å­¦æ—¶ï¼š50ï½100 å°æ—¶


## è¯¾ç¨‹èµ„æº

- è¯¾ç¨‹ç½‘ç«™ï¼š
- è¯¾ç¨‹è§†é¢‘ï¼š[YouTube](https://www.youtube.com/@AndrejKarpathy)
- è¯¾ç¨‹æ•™æï¼š
- è¯¾ç¨‹ä½œä¸šï¼š

## èµ„æºæ±‡æ€»

LLM general guidance

-[Intro to Large Language Models](https://www.youtube.com/watch?v=zjkBMFhNj_g)

### è§†é¢‘ä¸»é¢˜ï¼š[1hr Talk] Intro to Large Language Models


#### æ ¸å¿ƒå†…å®¹

##### 1. å¤§å‹è¯­è¨€æ¨¡å‹çš„å®šä¹‰ä¸ç»„æˆ
- **å®šä¹‰**ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ˜¯ä¸€ç§åŸºäºç¥ç»ç½‘ç»œçš„æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹æ–‡æœ¬åºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªå•è¯ã€‚
- **ç»„æˆ**ï¼šä»¥Llama 270bæ¨¡å‹ä¸ºä¾‹ï¼Œæ¨¡å‹ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š
  - **å‚æ•°æ–‡ä»¶**ï¼šåŒ…å«æ¨¡å‹çš„æƒé‡ï¼Œæ–‡ä»¶å¤§å°çº¦ä¸º140GBï¼ˆ700äº¿å‚æ•°ï¼Œæ¯ä¸ªå‚æ•°å ç”¨2å­—èŠ‚ï¼‰ã€‚
  - **è¿è¡Œä»£ç **ï¼šç”¨äºåŠ è½½å’Œè¿è¡Œå‚æ•°æ–‡ä»¶ï¼Œå¯ä½¿ç”¨Cè¯­è¨€å®ç°ï¼Œä»£ç é‡çº¦500è¡Œã€‚

##### 2. æ¨¡å‹è®­ç»ƒä¸æ¨ç†
- **æ¨¡å‹è®­ç»ƒ**ï¼š
  - **æ•°æ®é‡**ï¼šè®­ç»ƒæ•°æ®é‡å·¨å¤§ï¼Œçº¦10TBæ–‡æœ¬æ•°æ®ï¼Œé€šå¸¸æ¥è‡ªäº’è”ç½‘çˆ¬å–ã€‚
  - **è®¡ç®—èµ„æº**ï¼šéœ€è¦çº¦6000ä¸ªGPUï¼Œè®­ç»ƒæ—¶é—´çº¦12å¤©ï¼Œæˆæœ¬çº¦200ä¸‡ç¾å…ƒã€‚
  - **è®­ç»ƒè¿‡ç¨‹**ï¼šå°†å¤§é‡æ–‡æœ¬æ•°æ®å‹ç¼©æˆæ¨¡å‹å‚æ•°ï¼Œç±»ä¼¼äºâ€œå‹ç¼©æ–‡ä»¶â€ï¼Œä½†ä¸ºæœ‰æŸå‹ç¼©ã€‚
- **æ¨¡å‹æ¨ç†**ï¼š
  - **ç®€å•æ€§**ï¼šåœ¨MacBookä¸Šå³å¯è¿è¡Œï¼Œæ— éœ€äº’è”ç½‘è¿æ¥ã€‚
  - **é€Ÿåº¦**ï¼š700äº¿å‚æ•°æ¨¡å‹è¿è¡Œé€Ÿåº¦è¾ƒæ…¢ï¼Œä½†è¾ƒå°æ¨¡å‹ï¼ˆå¦‚7äº¿å‚æ•°ï¼‰è¿è¡Œé€Ÿåº¦è¾ƒå¿«ã€‚

##### 3. æ¨¡å‹çš„åº”ç”¨ä¸èƒ½åŠ›
- **æ–‡æœ¬ç”Ÿæˆ**ï¼šæ¨¡å‹å¯ä»¥æ ¹æ®è¾“å…¥çš„æ–‡æœ¬ç”Ÿæˆåç»­å†…å®¹ï¼Œä¾‹å¦‚å†™è¯—ã€ç”Ÿæˆæ–‡ç« ç­‰ã€‚
- **çŸ¥è¯†è¡¨ç¤º**ï¼šæ¨¡å‹é€šè¿‡é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œå­¦ä¹ äº†å¤§é‡å…³äºä¸–ç•Œçš„çŸ¥è¯†ï¼Œä½†è¿™ç§çŸ¥è¯†æ˜¯â€œå‹ç¼©â€å’Œâ€œæœ‰æŸâ€çš„ã€‚
- **æ¨¡å‹çš„å±€é™æ€§**ï¼šå°½ç®¡æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆçœ‹ä¼¼åˆç†çš„æ–‡æœ¬ï¼Œä½†å…¶è¾“å‡ºæœ‰æ—¶å¯èƒ½æ˜¯é”™è¯¯çš„æˆ–â€œå¹»è§‰â€ï¼ˆhallucinationï¼‰ã€‚

##### 4. æ¨¡å‹çš„è®­ç»ƒé˜¶æ®µ
- **é¢„è®­ç»ƒï¼ˆPre-trainingï¼‰**ï¼š
  - ä½¿ç”¨å¤§é‡äº’è”ç½‘æ–‡æ¡£è¿›è¡Œè®­ç»ƒï¼Œç›®æ ‡æ˜¯å­¦ä¹ è¯­è¨€çš„æ¨¡å¼å’ŒçŸ¥è¯†ã€‚
- **å¾®è°ƒï¼ˆFine-tuningï¼‰**ï¼š
  - ä½¿ç”¨äººå·¥æ ‡æ³¨çš„é—®ç­”æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä»¥â€œåŠ©æ‰‹â€çš„å½¢å¼å›ç­”é—®é¢˜ã€‚
  - å¾®è°ƒé˜¶æ®µæ›´æ³¨é‡è´¨é‡è€Œéæ•°é‡ï¼Œæ•°æ®é‡ç›¸å¯¹è¾ƒå°‘ä½†è´¨é‡æ›´é«˜ã€‚

##### 5. æ¨¡å‹çš„ä¼˜åŒ–ä¸æ”¹è¿›
- **å¤šæ¨¡æ€èƒ½åŠ›**ï¼šæ¨¡å‹ä¸ä»…èƒ½å¤Ÿç”Ÿæˆæ–‡æœ¬ï¼Œè¿˜èƒ½ç”Ÿæˆå›¾åƒã€å¤„ç†éŸ³é¢‘ç­‰ã€‚
- **å·¥å…·ä½¿ç”¨**ï¼šæ¨¡å‹èƒ½å¤Ÿåˆ©ç”¨å¤–éƒ¨å·¥å…·ï¼ˆå¦‚æœç´¢å¼•æ“ã€è®¡ç®—å™¨ç­‰ï¼‰æ¥å®Œæˆä»»åŠ¡ï¼Œç±»ä¼¼äºäººç±»ä½¿ç”¨å·¥å…·è§£å†³é—®é¢˜ã€‚
- **ç³»ç»Ÿä¸€ä¸ç³»ç»ŸäºŒæ€ç»´**ï¼šå½“å‰æ¨¡å‹ä¸»è¦ä¾èµ–å¿«é€Ÿã€ç›´è§‰çš„ç³»ç»Ÿä¸€æ€ç»´ï¼Œæœªæ¥å¯èƒ½å‘å±•å‡ºæ›´å¤æ‚çš„ã€ç±»ä¼¼äººç±»çš„ç³»ç»ŸäºŒæ€ç»´ã€‚

##### 6. æ¨¡å‹çš„å®‰å…¨æ€§ä¸æŒ‘æˆ˜
- **æ”»å‡»ç±»å‹**ï¼š
  - **è¶Šç‹±æ”»å‡»ï¼ˆJailbreak Attacksï¼‰**ï¼šé€šè¿‡ç‰¹å®šçš„æç¤ºæˆ–è§’è‰²æ‰®æ¼”ï¼Œä½¿æ¨¡å‹ç»•è¿‡å®‰å…¨é™åˆ¶ï¼Œè¾“å‡ºæœ‰å®³å†…å®¹ã€‚
  - **æç¤ºæ³¨å…¥æ”»å‡»ï¼ˆPrompt Injection Attacksï¼‰**ï¼šé€šè¿‡åœ¨è¾“å…¥ä¸­åµŒå…¥éšè—çš„æŒ‡ä»¤ï¼ŒåŠ«æŒæ¨¡å‹çš„è¾“å‡ºã€‚
  - **æ•°æ®æŠ•æ¯’æ”»å‡»ï¼ˆData Poisoning Attacksï¼‰**ï¼šé€šè¿‡åœ¨è®­ç»ƒæ•°æ®ä¸­æ’å…¥ç‰¹å®šçš„è§¦å‘è¯ï¼Œä½¿æ¨¡å‹åœ¨é‡åˆ°è¿™äº›è¯æ—¶äº§ç”Ÿé”™è¯¯çš„è¾“å‡ºã€‚

#### ç»“è®º
- å¤§å‹è¯­è¨€æ¨¡å‹å…·æœ‰å¼ºå¤§çš„æ–‡æœ¬ç”Ÿæˆå’ŒçŸ¥è¯†è¡¨ç¤ºèƒ½åŠ›ï¼Œä½†å…¶è®­ç»ƒå’Œè¿è¡Œéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºå’Œæ•°æ®ã€‚
- æ¨¡å‹çš„å¾®è°ƒé˜¶æ®µèƒ½å¤Ÿä½¿å…¶æ›´å¥½åœ°é€‚åº”ç‰¹å®šçš„ä»»åŠ¡å’Œæ ¼å¼ã€‚
- æ¨¡å‹çš„å¤šæ¨¡æ€èƒ½åŠ›å’Œå·¥å…·ä½¿ç”¨æ˜¯æœªæ¥å‘å±•çš„å…³é”®æ–¹å‘ã€‚
- æ¨¡å‹çš„å®‰å…¨æ€§æ˜¯ä¸€ä¸ªé‡è¦çš„æŒ‘æˆ˜ï¼Œéœ€è¦ä¸æ–­ç ”ç©¶å’Œæ”¹è¿›ã€‚


ä»¥ä¸‹æ˜¯å…³äºè§†é¢‘ã€ŠDeep Dive into LLMs like ChatGPT - YouTubeã€‹çš„è¯¦ç»†ç¬”è®°ï¼Œæ¶µç›–äº†è§†é¢‘å†…å®¹çš„å„ä¸ªæ–¹é¢ï¼ŒåŒ…æ‹¬å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä»‹ç»ã€è®­ç»ƒè¿‡ç¨‹ã€æŠ€æœ¯ç»†èŠ‚ä»¥åŠå®é™…åº”ç”¨ä¸­çš„è¡¨ç°å’Œé—®é¢˜ã€‚

### è§†é¢‘ä¸»é¢˜ä¸ç›®çš„
- **ä¸»é¢˜**ï¼šæ·±å…¥æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œå¦‚ChatGPTçš„å·¥ä½œåŸç†ã€è®­ç»ƒè¿‡ç¨‹ä»¥åŠå®ƒä»¬åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ã€‚
- **ç›®çš„**ï¼šä¸ºè§‚ä¼—æä¾›å¯¹LLMsçš„å…¨é¢ç†è§£ï¼ŒåŒ…æ‹¬å…¶æŠ€æœ¯åŸºç¡€ã€ä¼˜åŠ¿ã€å±€é™æ€§ä»¥åŠå¦‚ä½•æœ‰æ•ˆåˆ©ç”¨è¿™äº›æ¨¡å‹ã€‚

### è§†é¢‘å†…å®¹æ¦‚è¿°
1. **å¼•è¨€**
   - è§†é¢‘å¼€å¤´æåˆ°ï¼ŒLLMsï¼ˆå¦‚ChatGPTï¼‰åœ¨æŸäº›æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å…¶ä»–æ–¹é¢åˆ™è¡¨ç°ä¸ä½³ï¼ŒåŒæ—¶å­˜åœ¨ä¸€äº›éœ€è¦æ³¨æ„çš„â€œå°–é”è¾¹ç¼˜â€ï¼ˆsharp edgesï¼‰ã€‚
   - ä½œè€…å¸Œæœ›é€šè¿‡è§†é¢‘ä¸ºè§‚ä¼—æä¾›å…³äºè¿™äº›æ¨¡å‹çš„â€œå¿ƒæ™ºæ¨¡å‹â€ï¼ˆmental modelsï¼‰ï¼Œå¸®åŠ©è§‚ä¼—æ›´å¥½åœ°ç†è§£å’Œä½¿ç”¨LLMsã€‚

2. **LLMsçš„è®­ç»ƒè¿‡ç¨‹**
   - **é¢„è®­ç»ƒé˜¶æ®µï¼ˆPre-training Stageï¼‰**ï¼š
     - **æ•°æ®æ”¶é›†**ï¼šä»äº’è”ç½‘ä¸Šä¸‹è½½å’Œå¤„ç†å¤§é‡æ–‡æœ¬æ•°æ®ï¼Œæ„å»ºé«˜è´¨é‡çš„æ–‡æœ¬æ•°æ®é›†ã€‚ä¾‹å¦‚ï¼ŒHugging Faceçš„Fine Webæ•°æ®é›†åŒ…å«çº¦44TBçš„æ•°æ®ï¼Œç»è¿‡å¤šé˜¶æ®µå¤„ç†ï¼Œæœ€ç»ˆå¾—åˆ°çº¦15ä¸‡äº¿ä¸ªtokençš„æ•°æ®é›†ã€‚
     - **æ–‡æœ¬æå–ä¸è¿‡æ»¤**ï¼šé€šè¿‡URLè¿‡æ»¤ã€æ–‡æœ¬æå–ã€è¯­è¨€è¿‡æ»¤ç­‰æ­¥éª¤ï¼Œå»é™¤ä½è´¨é‡æˆ–ä¸ç›¸å…³å†…å®¹ï¼Œä¿ç•™é«˜è´¨é‡ã€å¤šæ ·åŒ–çš„æ–‡æœ¬ã€‚
     - **TokenåŒ–**ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯å¤„ç†çš„tokenåºåˆ—ã€‚ä½¿ç”¨Byte Pair Encodingï¼ˆBPEï¼‰ç®—æ³•å‡å°‘åºåˆ—é•¿åº¦ï¼Œå¢åŠ è¯æ±‡è¡¨å¤§å°ã€‚ä¾‹å¦‚ï¼ŒGPT-4ä½¿ç”¨çº¦100,000ä¸ªç¬¦å·ã€‚
   - **ç¥ç»ç½‘ç»œè®­ç»ƒ**ï¼š
     - **è¾“å…¥ä¸è¾“å‡º**ï¼šæ¨¡å‹çš„è¾“å…¥æ˜¯tokenåºåˆ—ï¼Œè¾“å‡ºæ˜¯å¯¹ä¸‹ä¸€ä¸ªtokençš„é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒã€‚
     - **è®­ç»ƒè¿‡ç¨‹**ï¼šé€šè¿‡å¤§é‡æ•°æ®è®­ç»ƒç¥ç»ç½‘ç»œï¼Œä½¿å…¶é¢„æµ‹çš„tokenåºåˆ—ä¸è®­ç»ƒæ•°æ®ä¸­çš„å®é™…åºåˆ—ä¸€è‡´ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹çš„å‚æ•°ä¼šä¸æ–­è°ƒæ•´ï¼Œä»¥æé«˜é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚
     - **ç¥ç»ç½‘ç»œå†…éƒ¨ç»“æ„**ï¼šä»‹ç»äº†ç¥ç»ç½‘ç»œçš„åŸºæœ¬ç»“æ„ï¼Œå¦‚Transformeræ¶æ„ï¼Œä»¥åŠå¦‚ä½•é€šè¿‡çŸ©é˜µè¿ç®—å’Œæ¿€æ´»å‡½æ•°è¿›è¡Œè®¡ç®—ã€‚

3. **LLMsçš„æ¨ç†è¿‡ç¨‹ï¼ˆInferenceï¼‰**
   - **ç”Ÿæˆæ–‡æœ¬**ï¼šåœ¨æ¨ç†é˜¶æ®µï¼Œæ¨¡å‹æ ¹æ®è¾“å…¥çš„tokenåºåˆ—ç”Ÿæˆæ–°çš„æ–‡æœ¬ã€‚é€šè¿‡é‡‡æ ·ä¸‹ä¸€ä¸ªtokençš„æ¦‚ç‡åˆ†å¸ƒï¼Œæ¨¡å‹å¯ä»¥ç”Ÿæˆè¿è´¯çš„æ–‡æœ¬ã€‚
   - **éšæœºæ€§ä¸å¤šæ ·æ€§**ï¼šç”±äºæ¨¡å‹çš„è¾“å‡ºæ˜¯æ¦‚ç‡åˆ†å¸ƒï¼Œæ¯æ¬¡ç”Ÿæˆçš„ç»“æœå¯èƒ½ä¸åŒï¼Œè¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿäº§ç”Ÿå¤šæ ·åŒ–çš„æ–‡æœ¬ã€‚

4. **LLMsçš„å®é™…åº”ç”¨ä¸å±€é™æ€§**
   - **ä¼˜åŠ¿**ï¼šLLMsåœ¨å¤„ç†è‡ªç„¶è¯­è¨€ä»»åŠ¡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„æ–‡æœ¬ï¼Œå¦‚å†™ä½œã€ç¿»è¯‘ã€é—®ç­”ç­‰ã€‚
   - **å±€é™æ€§**ï¼š
     - **å¹»è§‰ï¼ˆHallucinationsï¼‰**ï¼šæ¨¡å‹å¯èƒ½ä¼šç”Ÿæˆè™šå‡æˆ–ä¸å‡†ç¡®çš„ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œå½“æ¨¡å‹è¢«é—®åŠä¸€ä¸ªä¸å­˜åœ¨çš„äººç‰©æ—¶ï¼Œå®ƒå¯èƒ½ä¼šç¼–é€ ä¸€ä¸ªçœ‹ä¼¼åˆç†çš„å›ç­”ã€‚
     - **è®¡ç®—èµ„æºéœ€æ±‚**ï¼šè®­ç»ƒå’Œè¿è¡Œå¤§å‹è¯­è¨€æ¨¡å‹éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºï¼Œé€šå¸¸éœ€è¦ä½¿ç”¨é«˜æ€§èƒ½çš„GPUé›†ç¾¤ã€‚
     - **æ•°æ®ä¾èµ–æ€§**ï¼šæ¨¡å‹çš„æ€§èƒ½ä¾èµ–äºè®­ç»ƒæ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚å¦‚æœè®­ç»ƒæ•°æ®å­˜åœ¨åå·®æˆ–ä¸å‡†ç¡®ï¼Œæ¨¡å‹çš„è¾“å‡ºä¹Ÿå¯èƒ½å—åˆ°å½±å“ã€‚

5. **LLMsçš„å¿ƒç†å­¦ç‰¹æ€§ï¼ˆLLM Psychologyï¼‰**
   - **è‡ªæˆ‘è®¤çŸ¥ï¼ˆSense of Selfï¼‰**ï¼šæ¨¡å‹æ²¡æœ‰æŒä¹…çš„è‡ªæˆ‘è®¤çŸ¥ï¼Œæ¯æ¬¡å¯¹è¯éƒ½æ˜¯ä»å¤´å¼€å§‹çš„ã€‚
   - **é—®é¢˜è§£å†³èƒ½åŠ›**ï¼šæ¨¡å‹åœ¨è§£å†³å¤æ‚é—®é¢˜æ—¶è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ç®€å•é—®é¢˜ä¸Šå¯èƒ½ä¼šå‡ºç°é”™è¯¯ã€‚ä¾‹å¦‚ï¼Œæ¨¡å‹å¯èƒ½åœ¨è§£å†³æ•°å­¦å¥¥æ—åŒ¹å…‹é—®é¢˜æ—¶è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨æ¯”è¾ƒä¸¤ä¸ªæ•°å­—å¤§å°æ—¶å´å¯èƒ½å‡ºç°é”™è¯¯ã€‚
   - **å·¥å…·ä½¿ç”¨ï¼ˆTool Useï¼‰**ï¼šæ¨¡å‹å¯ä»¥é€šè¿‡è°ƒç”¨å¤–éƒ¨å·¥å…·ï¼ˆå¦‚æœç´¢å¼•æ“ã€ä»£ç è§£é‡Šå™¨ï¼‰æ¥æé«˜å…¶è§£å†³é—®é¢˜çš„èƒ½åŠ›ã€‚ä¾‹å¦‚ï¼Œå½“æ¨¡å‹ä¸ç¡®å®šæŸä¸ªé—®é¢˜çš„ç­”æ¡ˆæ—¶ï¼Œå®ƒå¯ä»¥è°ƒç”¨æœç´¢å¼•æ“è·å–æ›´å¤šä¿¡æ¯ã€‚

6. **å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰**
   - å¼ºåŒ–å­¦ä¹ æ˜¯LLMsè®­ç»ƒçš„ç¬¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼Œæ—¨åœ¨é€šè¿‡å®è·µé—®é¢˜æ¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚
   - åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæ¨¡å‹ä¼šå°è¯•å¤šç§è§£å†³æ–¹æ¡ˆï¼Œå¹¶æ ¹æ®æœ€ç»ˆç­”æ¡ˆçš„æ­£ç¡®æ€§æ¥è°ƒæ•´å…¶è¡Œä¸ºã€‚
   - é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œæ¨¡å‹å¯ä»¥å‘ç°æ›´æœ‰æ•ˆçš„è§£å†³é—®é¢˜çš„ç­–ç•¥ï¼Œæé«˜å…¶æ¨ç†èƒ½åŠ›ã€‚

### è§†é¢‘æ€»ç»“
- è§†é¢‘è¯¦ç»†ä»‹ç»äº†LLMsçš„è®­ç»ƒè¿‡ç¨‹ã€æŠ€æœ¯ç»†èŠ‚ä»¥åŠåœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°å’Œé—®é¢˜ã€‚
- ä½œè€…å¼ºè°ƒï¼Œå°½ç®¡LLMsåœ¨æŸäº›ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬ä»ç„¶å­˜åœ¨å±€é™æ€§ï¼Œéœ€è¦è°¨æ…ä½¿ç”¨ã€‚
- æœªæ¥çš„å‘å±•æ–¹å‘åŒ…æ‹¬å¤šæ¨¡æ€æ¨¡å‹ï¼ˆå¤„ç†æ–‡æœ¬ã€éŸ³é¢‘å’Œå›¾åƒï¼‰ã€é•¿æœŸä»»åŠ¡æ‰§è¡Œä»¥åŠæ›´é«˜æ•ˆçš„è®­ç»ƒå’Œæ¨ç†æ–¹æ³•ã€‚

### é€‚ç”¨å»ºè®®
- **å¼€å‘è€…**ï¼šäº†è§£LLMsçš„è®­ç»ƒè¿‡ç¨‹å’ŒæŠ€æœ¯ç»†èŠ‚ï¼Œæœ‰åŠ©äºæ›´å¥½åœ°åˆ©ç”¨è¿™äº›æ¨¡å‹è¿›è¡Œåº”ç”¨å¼€å‘ã€‚
- **ç ”ç©¶äººå‘˜**ï¼šè§†é¢‘ä¸­çš„å†…å®¹å¯ä»¥ä¸ºç ”ç©¶äººå‘˜æä¾›å…³äºLLMsçš„æœ€æ–°ç ”ç©¶è¿›å±•å’Œæœªæ¥å‘å±•æ–¹å‘çš„è§è§£ã€‚
- **æ™®é€šç”¨æˆ·**ï¼šé€šè¿‡äº†è§£LLMsçš„å·¥ä½œåŸç†å’Œå±€é™æ€§ï¼Œç”¨æˆ·å¯ä»¥æ›´åˆç†åœ°ä½¿ç”¨è¿™äº›æ¨¡å‹ï¼Œå¹¶å¯¹å…¶è¾“å‡ºä¿æŒæ‰¹åˆ¤æ€§æ€ç»´ã€‚

## è¯¾ç¨‹æ ¸å¿ƒæ¶æ„

### 1. ç¥ç»ç½‘ç»œåŸºç¡€ä¸å®ç°è·¯å¾„

è¯¥ç³»åˆ—é‡‡ç”¨**"è‡ªåº•å‘ä¸Š"**çš„æ•™å­¦èŒƒå¼ï¼Œä»¥Pythonè¯­è¨€ä¸ºå·¥å…·é“¾ï¼Œæ„å»ºä»åŸºç¡€æ•°å­¦è¿ç®—åˆ°å®Œæ•´GPTæ¨¡å‹çš„å®Œæ•´çŸ¥è¯†ä½“ç³»ã€‚è¯¾ç¨‹æŠ€æœ¯æ ˆæ¼”è¿›è·¯å¾„å¯æ¦‚æ‹¬ä¸ºï¼š

#### å¾®æ¢¯åº¦å¼•æ“ â†’ å¤šå±‚æ„ŸçŸ¥æœº â†’ å·ç§¯ç½‘ç»œ â†’ Transformer â†’ GPTæ¶æ„ â†’ åˆ†è¯ç³»ç»Ÿ

é€šè¿‡microgradæ¨¡å—å®ç°è‡ªåŠ¨å¾®åˆ†å¼•æ“ï¼ˆçº¦200è¡ŒPythonä»£ç ï¼‰ï¼Œå»ºç«‹å¯¹åå‘ä¼ æ’­ç®—æ³•çš„ç›´è§‚ç†è§£[1][3]ã€‚åœ¨makemoreç³»åˆ—å®éªŒä¸­ï¼Œé€æ­¥å¼•å…¥æ‰¹æ¬¡å½’ä¸€åŒ–ã€æ®‹å·®è¿æ¥ç­‰ç°ä»£æ·±åº¦å­¦ä¹ ç»„ä»¶ï¼Œæœ€ç»ˆåœ¨nanoGPTé¡¹ç›®ä¸­å®ç°å®Œæ•´çš„Transformeræ¶æ„[2][3]ã€‚è¿™ç§æ¸è¿›å¼æ•™å­¦æ³•ä½¿å¾—å¤æ‚æ¦‚å¿µå¦‚ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰å’Œå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆMulti-Head Attentionï¼‰çš„æ•°å­¦åŸç†å¾—ä»¥æ¸…æ™°å±•ç°ã€‚

### 2. Transformeræ¶æ„æŠ€æœ¯è§£æ

åœ¨[Let's build GPT](https://www.youtube.com/watch?v=kCc8FmEb1nY)ä¸“é¢˜è®²åº§ä¸­ï¼ŒKarpathyé€è¡Œç¼–ç æ¼”ç¤ºäº†Transformeræ ¸å¿ƒç»„ä»¶ï¼š

```python
class MultiHeadAttention(nn.Module):
    def __init__(self, num_heads, head_size):
        super().__init__()
        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])
        self.proj = nn.Linear(n_embd, n_embd)  # æŠ•å½±å±‚ç¡®ä¿ç»´åº¦åŒ¹é…
    
    def forward(self, x):
        out = torch.cat([h(x) for h in self.heads], dim=-1)
        out = self.proj(out)
        return out
```

è¯¥å®ç°æ­ç¤ºäº†æ³¨æ„åŠ›å¤´çš„å¹¶è¡Œè®¡ç®—æœºåˆ¶ï¼Œæ¯ä¸ªå¤´ç‹¬ç«‹å¤„ç†è¾“å…¥å‘é‡çš„å­ç©ºé—´ç‰¹å¾ï¼Œæœ€åé€šè¿‡çº¿æ€§æŠ•å½±æ•´åˆä¿¡æ¯[2]ã€‚è§†é¢‘ä¸­ç‰¹åˆ«å¼ºè°ƒäº†LayerNormä¸BatchNormçš„å·®å¼‚ï¼šå‰è€…åœ¨ç‰¹å¾ç»´åº¦è¿›è¡Œå½’ä¸€åŒ–ï¼Œé€‚ç”¨äºåºåˆ—æ•°æ®ï¼›åè€…åœ¨æ‰¹æ¬¡ç»´åº¦å½’ä¸€åŒ–ï¼Œæ›´é€‚ç”¨äºå›ºå®šé•¿åº¦è¾“å…¥ã€‚

### 3. åˆ†è¯ç³»ç»Ÿå®ç°ç»†èŠ‚

è¯¾ç¨‹ä¸­åŒ…å«å®Œæ•´çš„å­—èŠ‚å¯¹ç¼–ç ï¼ˆBPEï¼‰å®ç°æ•™ç¨‹ï¼Œå…³é”®ç®—æ³•æ­¥éª¤åŒ…æ‹¬ï¼š

1. ç»Ÿè®¡æ‰€æœ‰ç›¸é‚»å­—ç¬¦å¯¹é¢‘ç‡
2. åˆå¹¶æœ€é«˜é¢‘å­—ç¬¦å¯¹å½¢æˆæ–°è¯å…ƒ
3. è¿­ä»£æ‰§è¡Œç›´è‡³è¾¾åˆ°é¢„è®¾è¯æ±‡é‡

å®éªŒæ˜¾ç¤ºï¼Œåœ¨èå£«æ¯”äºšæ–‡æœ¬æ•°æ®ä¸Šï¼Œç»è¿‡10,000æ¬¡åˆå¹¶æ“ä½œåï¼Œåˆ†è¯é”™è¯¯ç‡ä»åˆå§‹çš„23%ä¸‹é™è‡³4.5%[1]ã€‚è¿™ç§æ•°æ®é©±åŠ¨çš„æ–¹æ³•æœ‰æ•ˆå¹³è¡¡äº†è¯è¡¨è§„æ¨¡ä¸è¯­ä¹‰ç²’åº¦ï¼Œä¸ºåç»­è¯­è¨€æ¨¡å‹è®­ç»ƒå¥ å®šåŸºç¡€ã€‚

### 4. nanoGPTå·¥ç¨‹å®è·µ

nanoGPTé¡¹ç›®å±•ç°äº†å·¥ä¸šçº§è¯­è¨€æ¨¡å‹çš„ç®€åŒ–å®ç°ï¼Œå…¶è¶…å‚æ•°é…ç½®ç­–ç•¥å…·æœ‰é‡è¦å‚è€ƒä»·å€¼ï¼š

| å‚æ•°            | å…¸å‹å€¼     | ä½œç”¨æœºåˆ¶               |
|-----------------|------------|----------------------|
| ä¸Šä¸‹æ–‡é•¿åº¦       | 256 tokens | æ§åˆ¶æ¨¡å‹è®°å¿†å®¹é‡       |
| åµŒå…¥ç»´åº¦         | 384        | ç‰¹å¾è¡¨å¾ç©ºé—´å¤æ‚åº¦     |
| æ³¨æ„åŠ›å¤´æ•°       | 6          | å¹¶è¡Œç‰¹å¾æå–èƒ½åŠ›       |
| æ®‹å·®ä¸¢å¼ƒç‡       | 0.2        | é˜²æ­¢è¿‡æ‹Ÿåˆæ­£åˆ™åŒ–æ‰‹æ®µ   |
| å­¦ä¹ ç‡è¡°å‡ç­–ç•¥   | cosine     | ä¼˜åŒ–è®­ç»ƒç¨³å®šæ€§         |

åœ¨Lambda GPUå®ä¾‹ä¸Šï¼Œå®Œæ•´è®­ç»ƒå‘¨æœŸçº¦15åˆ†é’Ÿå¯è·å¾—éªŒè¯æŸå¤±1.48ï¼Œç”Ÿæˆæ–‡æœ¬å·²å…·å¤‡åŸºæœ¬è¯­æ³•ç»“æ„[2]ã€‚è¯¥å®ç°ç‰¹åˆ«è®¾è®¡äº†åˆ†é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼šé¢„è®­ç»ƒé˜¶æ®µä½¿ç”¨å¤§è§„æ¨¡æ–‡æœ¬è¯­æ–™ï¼ˆçº¦300B tokensï¼‰ï¼Œå¾®è°ƒé˜¶æ®µé€šè¿‡æŒ‡ä»¤ä¼˜åŒ–å®ç°å¯¹è¯èƒ½åŠ›ã€‚

## å…³é”®æŠ€æœ¯ç»„ä»¶æ¼”è¿›

### 1. è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¼˜åŒ–è·¯å¾„

```mermaid
graph LR
A[æœ´ç´ æ³¨æ„åŠ›O(nÂ²)] --> B[åˆ†å—è®¡ç®—ä¼˜åŒ–]
B --> C[FlashAttentionç®—æ³•]
C --> D[å¤šå¤´å¹¶è¡Œå¤„ç†]
D --> E[KV Cacheæ¨ç†åŠ é€Ÿ]
```

è¯¥æ¼”è¿›è·¯çº¿ä½¿è®¡ç®—å¤æ‚åº¦ä»åŸå§‹Transformerçš„O(nÂ²)é™ä½è‡³å®é™…å¯æ¥å—çš„O(n log n)[2]ã€‚è§†é¢‘ä¸­é€šè¿‡çŸ©é˜µä¹˜æ³•å¯è§†åŒ–å±•ç¤ºäº†æ³¨æ„åŠ›æƒé‡å¦‚ä½•åŠ¨æ€èšç„¦å…³é”®ä¸Šä¸‹æ–‡ä½ç½®ã€‚

### 2. ä½ç½®ç¼–ç æ–¹æ¡ˆå¯¹æ¯”

æ–¹æ¡ˆ | å…¬å¼ | ä¼˜ç‚¹ | å±€é™æ€§
---|---|---|---
ç»å¯¹ä½ç½®ç¼–ç  | $$ PE(pos,2i) = \sin(pos/10000^{2i/d}) $$ | æ˜ç¡®ä½ç½®ä¿¡æ¯ | é•¿åº¦å¤–æ¨èƒ½åŠ›å·®
ç›¸å¯¹ä½ç½®ç¼–ç  | $$ a_{ij} = x_iW^Q(W^K)^Tx_j + x_iW^Qr_{i-j} $$ | æ›´å¥½æ•æ‰å±€éƒ¨å…³ç³» | å®ç°å¤æ‚åº¦é«˜
æ—‹è½¬ä½ç½®ç¼–ç  | $$ q_m^Tk_n = Re[ e^{i(mÎ¸ - nÎ¸)} q_m^Tk_n ] $$ | ä¿æŒå†…ç§¯ç¨³å®šæ€§ | éœ€è¦å®šåˆ¶åŒ–å®ç°

å®éªŒæ•°æ®æ˜¾ç¤ºï¼Œåœ¨æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œæ—‹è½¬ä½ç½®ç¼–ç ï¼ˆRoPEï¼‰å¯ä½¿å›°æƒ‘åº¦é™ä½çº¦15%[2]ã€‚

## å®è·µè®­ç»ƒå»ºè®®

### 1. ç¡¬ä»¶èµ„æºé…ç½®ç­–ç•¥

```python
# åˆ†å¸ƒå¼è®­ç»ƒé…ç½®ç¤ºä¾‹
parallel_config = {
    "tensor_parallel_degree": 8,  # æ¨¡å‹å¹¶è¡Œç»´åº¦
    "pipeline_parallel_degree": 4, # æµæ°´çº¿å¹¶è¡Œç»´åº¦ 
    "micro_batch_size": 16,        # å¾®æ‰¹æ¬¡å¤§å°
    "gradient_accumulation_steps": 32
}
```

### 2. è°ƒè¯•ä¸ä¼˜åŒ–æŠ€æœ¯
- **æ¢¯åº¦è£å‰ª**ï¼šè®¾ç½®é˜ˆå€¼`max_grad_norm=1.0`é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
- **æ··åˆç²¾åº¦è®­ç»ƒ**ï¼šä½¿ç”¨`torch.cuda.amp`æ¨¡å—èŠ‚çº¦æ˜¾å­˜40%
- **æ¿€æ´»æ£€æŸ¥ç‚¹**ï¼šé€šè¿‡`torch.utils.checkpoint`é™ä½æ˜¾å­˜æ¶ˆè€—50%
- **å­¦ä¹ ç‡æ¢æµ‹**ï¼šæ‰§è¡Œçº¿æ€§æ‰«ææ‰¾å‡ºæœ€ä¼˜åˆå§‹å­¦ä¹ ç‡

åœ¨nanoGPTé¡¹ç›®ä¸­ï¼Œå¼•å…¥LayerScaleæŠ€æœ¯ï¼ˆæ¯å±‚è¾“å‡ºä¹˜ä»¥å¯å­¦ä¹ æ ‡é‡ï¼‰å¯ä½¿è®­ç»ƒç¨³å®šæ€§æå‡30%[2]ã€‚

## æ‰©å±•åº”ç”¨åœºæ™¯

### 1. ä»£ç ç”Ÿæˆä¼˜åŒ–æ¡ˆä¾‹
```python
def code_completion(prompt: str, temperature=0.8):
    tokens = tokenizer.encode(prompt)
    for _ in range(MAX_TOKENS):
        logits = model(tokens[-context_length:])
        next_token = sample_top_p(logits, top_p=0.95)
        tokens.append(next_token)
        if next_token == EOS: break
    return tokenizer.decode(tokens)
```
è¯¥ç®—æ³•é‡‡ç”¨Top-pé‡‡æ ·ï¼ˆnucleus samplingï¼‰ç­–ç•¥ï¼Œåœ¨ä¿æŒç”Ÿæˆå¤šæ ·æ€§çš„åŒæ—¶å‡å°‘è¯­æ³•é”™è¯¯ã€‚åœ¨Pythonä»£ç è¡¥å…¨ä»»åŠ¡ä¸­ï¼Œç›¸æ¯”è´ªå©ªè§£ç å¯ä½¿æ­£ç¡®ç‡æå‡28%[1]ã€‚

## å­¦ä¹ è·¯çº¿å›¾

é˜¶æ®µ | å†…å®¹ | å»ºè®®æ—¶é•¿ | å…³é”®äº§å‡º
---|---|---|---
åŸºç¡€æŒæ¡ | microgradå®ç°/MLPè®­ç»ƒ | 20å°æ—¶ | æ‰‹å†™æ•°å­—è¯†åˆ«æ¨¡å‹
è¿›é˜¶å®è·µ | Transformerç¼–ç å™¨/è§£ç å™¨ | 40å°æ—¶ | æœºå™¨ç¿»è¯‘åŸå‹ç³»ç»Ÿ
ä¸“ä¸šæ·±åŒ– | åˆ†å¸ƒå¼è®­ç»ƒ/RLHF | 60å°æ—¶ | é¢†åŸŸä¸“ç”¨å¯¹è¯ç³»ç»Ÿ
ç”Ÿäº§éƒ¨ç½² | æ¨¡å‹é‡åŒ–/æœåŠ¡åŒ– | 30å°æ—¶ | REST APIæœåŠ¡ç«¯ç‚¹

å»ºè®®é…åˆã€ŠThe Annotated Transformerã€‹ç­‰å¼€æºé¡¹ç›®è¿›è¡Œå¯¹ç…§å­¦ä¹ ï¼Œå¹¶åœ¨Kaggleå¹³å°å‚ä¸LLMç›¸å…³ç«èµ›ä»¥å·©å›ºæŠ€èƒ½[1][3]ã€‚

Citations:
[1] https://github.com/chizkidd/Karpathy-Neural-Networks-Zero-to-Hero
[2] https://www.youtube.com/watch?v=kCc8FmEb1nY
[3] https://karpathy.ai/zero-to-hero.html
[4] https://karpathy.ai
[5] https://www.reddit.com/r/learnmachinelearning/comments/17bmpy7/decreasing_loss_with_incorrectly_applied_softmax/
[6] https://www.reddit.com/r/learnmachinelearning/comments/1dsg6mi/those_who_loved_andrej_karpathys_zero_to_hero/
[7] https://podwise.ai/dashboard/collections/14
[8] https://news.ycombinator.com/item?id=34591998
[9] https://www.youtube.com/watch?v=F53Tt_vNLdg
[10] https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ
[11] https://www.youtube.com/andrejkarpathy
[12] https://github.com/karpathy/llm.c
[13] https://github.com/karpathy/nanoGPT
[14] https://news.ycombinator.com/item?id=40502693