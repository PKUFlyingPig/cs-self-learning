# UC Berkeley CS 194/294-267: Understanding Large Language Models: Foundations and Safety

## Course Introduction

- **University**: UC Berkeley
- **Prerequisites**: CS 182/282A Deep Neural Networks or equivalent, with hands-on deep learning experience.
- **Course Difficulty**: ðŸŒŸðŸŒŸðŸŒŸðŸŒŸðŸŒŸðŸŒŸ
- **Course Website**: [Understanding Large Language Models](http://rdi.berkeley.edu/understanding_llms/s24)

"Understanding Large Language Models: Foundations and Safety" is a Spring 2024 course at UC Berkeley, co-taught by **Professor Dawn Song** and **Dan Hendrycks**, with **Yu Gai** as the GSI. This course explores the foundational principles, interpretability, scaling laws, and risks associated with large language models (LLMs) such as ChatGPT.

The course provides a rigorous introduction to LLMs, discussing their emergence, limitations, and potential risks, as well as methods for safer and more beneficial applications. Topics covered include:

- Foundations of LLMs
- Interpretability
- Scaling laws
- Adversarial robustness
- AI alignment and governance
- Privacy, watermarking, and Trojans
- Agency, emergence, reasoning, and mathematics
- Evaluation and benchmarking


